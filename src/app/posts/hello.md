---
title: "Hello World"
date: "2024-01-01"
---
In 2024, we're going to try and write our ideas down more.

<br>

### Ideas Early This Year

<br>

Clever `Assistant` retrieval of highly annotated documents that are embedded in vectordbs like Chroma, Redis, and/or Turbopuffer. Assistants can call functions; it's time they use that to make metadata-filtered queries from natural language. Assistants should also have tools to store typed key excerpts from interactions as documents, to make them referenceable in the future.

<br>

Application state is just a `type[BaseModel]` on a thing that can patch its own schema with knowledge from the world. See this example.

<br>

Imagine Celery workers as circumstantial nodes in a graph. They can be invoked at any time, from anywhere. What if, hypothetically speaking, you could sic a hivemind of autonomous workers on a problem that compete evolutionarily to curate a central distillation of useful knowledge, which is in turn broadcasted back out to workers as the updated "common sense"?
